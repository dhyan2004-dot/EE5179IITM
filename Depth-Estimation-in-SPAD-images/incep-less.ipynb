{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":97555,"databundleVersionId":11670858,"sourceType":"competition"}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport cv2\nimport torch\nimport torch.nn as nn\nimport pandas as pd\nimport numpy as np\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\nfrom PIL import Image\nfrom tqdm import tqdm\nimport shutil\n\n# ====================\n# Convert Images to CSV with Metadata\n# ====================\ndef images_to_csv_with_metadata(image_folder, output_csv):\n    data = []\n    for idx, filename in enumerate(sorted(os.listdir(image_folder))):\n        if filename.endswith(\".png\"):\n            filepath = os.path.join(image_folder, filename)\n            image = cv2.imread(filepath, cv2.IMREAD_UNCHANGED)\n            image = cv2.resize(image, (128, 128))\n            image = image / 255.\n            image = (image - np.min(image)) / (np.max(image) - np.min(image) + 1e-6)\n            image = np.uint8(image * 255.)\n            image_flat = image.flatten()\n            row = [idx, filename] + image_flat.tolist()\n            data.append(row)\n\n    num_columns = len(data[0]) - 2 if data else 0\n    column_names = [\"id\", \"ImageID\"] + [indx for indx in range(num_columns)]\n    df = pd.DataFrame(data, columns=column_names)\n    df.to_csv(output_csv, index=False)\n\n# ====================\n# Custom Dataset\n# ====================\nclass SPADDataset(Dataset):\n    def __init__(self, image_dir, depth_dir=None, transform=None):\n        self.image_dir = image_dir\n        self.depth_dir = depth_dir\n        self.transform = transform\n        self.images = sorted(os.listdir(image_dir))\n\n    def __len__(self):\n        return len(self.images)\n\n    def __getitem__(self, idx):\n        img_path = os.path.join(self.image_dir, self.images[idx])\n        image = Image.open(img_path).convert('L')  # SPAD images (binary/grayscale)\n\n        if self.transform:\n            image = self.transform(image)\n\n        if self.depth_dir:\n            depth_path = os.path.join(self.depth_dir, self.images[idx])\n            depth = Image.open(depth_path).convert('L')\n            if self.transform:\n                depth = self.transform(depth)\n            return image, depth\n\n        return image, self.images[idx]\n\n# ====================\n# Custom GoogLeNet Block\n# ====================\nclass InceptionBlock(nn.Module):\n    def __init__(self, in_channels):\n        super(InceptionBlock, self).__init__()\n        self.branch1x1 = nn.Conv2d(in_channels, 32, kernel_size=1)\n        self.branch3x3 = nn.Sequential(\n            nn.Conv2d(in_channels, 32, kernel_size=1),\n            nn.Conv2d(32, 48, kernel_size=3, padding=1)\n        )\n        self.branch5x5 = nn.Sequential(\n            nn.Conv2d(in_channels, 8, kernel_size=1),\n            nn.Conv2d(8, 16, kernel_size=5, padding=2)\n        )\n        self.branch_pool = nn.Sequential(\n            nn.MaxPool2d(kernel_size=3, stride=1, padding=1),\n            nn.Conv2d(in_channels, 16, kernel_size=1)\n        )\n\n    def forward(self, x):\n        return torch.cat([\n            self.branch1x1(x),\n            self.branch3x3(x),\n            self.branch5x5(x),\n            self.branch_pool(x)\n        ], dim=1)\n\n# ====================\n# GoogLeNet-Style DepthNet\n# ====================\nclass SPADDepthNet(nn.Module):\n    def __init__(self):\n        super(SPADDepthNet, self).__init__()\n        self.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3)\n        self.pool1 = nn.MaxPool2d(3, 2, padding=1)\n\n        self.conv2 = nn.Conv2d(64, 64, kernel_size=1)\n        self.conv3 = nn.Conv2d(64, 192, kernel_size=3, padding=1)\n        self.pool2 = nn.MaxPool2d(3, 2, padding=1)\n\n        self.inception3a = InceptionBlock(192)\n        self.inception3b = InceptionBlock(112)\n        self.pool3 = nn.MaxPool2d(3, 2, padding=1)\n\n        self.inception4a = InceptionBlock(112)\n        self.inception4b = InceptionBlock(112)\n        self.inception4c = InceptionBlock(112)\n        self.pool4 = nn.MaxPool2d(3, 2, padding=1)\n\n        self.final_conv = nn.Conv2d(112, 1, kernel_size=1)\n        self.weights = nn.Parameter(torch.ones(5))\n\n    def forward(self, x):\n        x = self.pool1(torch.relu(self.conv1(x)))\n        x = torch.relu(self.conv2(x))\n        x = self.pool2(torch.relu(self.conv3(x)))\n\n        s1 = self.inception3a(x)\n        s2 = self.inception3b(s1)\n        x = self.pool3(s2)\n\n        s3 = self.inception4a(x)\n        s4 = self.inception4b(s3)\n        s5 = self.inception4c(s4)\n\n        target_size = s1.shape[2:]\n        side_outputs = [\n            nn.functional.interpolate(s, size=target_size, mode='bilinear', align_corners=False)\n            for s in [s1, s2, s3, s4, s5]\n        ]\n\n        combined = sum(w * s for w, s in zip(self.weights, side_outputs))\n        out = self.final_conv(combined)\n        out = nn.functional.interpolate(out, size=(224, 224), mode='bilinear', align_corners=False)\n        return out\n\n# ====================\n# Training and Evaluation\n# ====================\ndef train(model, dataloader, optimizer, criterion, device):\n    model.train()\n    running_loss = 0\n    for img, depth in tqdm(dataloader):\n        img, depth = img.to(device), depth.to(device)\n        optimizer.zero_grad()\n        output = model(img)\n        loss = criterion(output, depth)\n        loss.backward()\n        optimizer.step()\n        running_loss += loss.item()\n    return running_loss / len(dataloader)\n\ndef evaluate(model, dataloader, criterion, device):\n    model.eval()\n    running_loss = 0\n    with torch.no_grad():\n        for img, depth in tqdm(dataloader):\n            img, depth = img.to(device), depth.to(device)\n            output = model(img)\n            loss = criterion(output, depth)\n            running_loss += loss.item()\n    return running_loss / len(dataloader)\n\nclass RMSELoss(nn.Module):\n    def __init__(self):\n        super(RMSELoss, self).__init__()\n        self.mse = nn.MSELoss()\n\n    def forward(self, y_pred, y_true):\n        return torch.sqrt(self.mse(y_pred, y_true))\n\n\n# ====================\n# Prediction + CSV Generation\n# ====================\ndef predict_and_save(model, dataloader, device, save_path=\"submission.csv\", temp_output_folder=\"temp_predictions\"):\n    model.eval()\n    os.makedirs(temp_output_folder, exist_ok=True)\n    filenames = []\n\n    with torch.no_grad():\n        for img, fname in tqdm(dataloader):\n            img = img.to(device)\n            output = model(img).squeeze().cpu().numpy()  # (B, H, W)\n\n            for i in range(output.shape[0]):\n                filename = fname[i]\n                pred_image = output[i]\n                pred_image = (pred_image - pred_image.min()) / (pred_image.max() - pred_image.min() + 1e-6)\n                pred_image = (pred_image * 255).astype(np.uint8)\n                save_path_img = os.path.join(temp_output_folder, filename)\n                cv2.imwrite(save_path_img, pred_image)\n                filenames.append(filename)\n\n    # Convert to CSV using the earlier function\n    images_to_csv_with_metadata(temp_output_folder, save_path)\n\n    # Optional: delete temporary folder\n    shutil.rmtree(temp_output_folder)\n    print(f\"Saved predictions to {save_path}\")\n\n# ====================\n# Main Runner\n# ====================\ndef main():\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n    transform = transforms.Compose([\n        transforms.Resize((224, 224)),\n        transforms.ToTensor()\n    ])\n\n    base_path = \"/kaggle/input/ee-5179-modern-computer-vision-course-competition/competition-data\"\n\n    train_dataset = SPADDataset(os.path.join(base_path, \"training-images\"),\n                                os.path.join(base_path, \"training-depths\"),\n                                transform)\n    val_dataset = SPADDataset(os.path.join(base_path, \"validation-images\"),\n                              os.path.join(base_path, \"validation-depths\"),\n                              transform)\n    test_dataset = SPADDataset(os.path.join(base_path, \"testing-images\"),\n                               None,\n                               transform)\n\n    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n    val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n    test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n\n    model = SPADDepthNet().to(device)\n    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n    criterion = RMSELoss()\n\n    for epoch in range(1, 4):\n        print(f\"\\nEpoch {epoch}\")\n        train_loss = train(model, train_loader, optimizer, criterion, device)\n        val_loss = evaluate(model, val_loader, criterion, device)\n        print(f\"Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n\n    predict_and_save(model, test_loader, device, save_path=\"submission_incep(3).csv\")\n\nif __name__ == \"__main__\":\n    main()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T22:34:45.355483Z","iopub.execute_input":"2025-04-27T22:34:45.355708Z","iopub.status.idle":"2025-04-27T22:38:25.581792Z","shell.execute_reply.started":"2025-04-27T22:34:45.355684Z","shell.execute_reply":"2025-04-27T22:38:25.581151Z"}},"outputs":[{"name":"stdout","text":"\nEpoch 1\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 418/418 [01:29<00:00,  4.70it/s]\n100%|██████████| 53/53 [00:09<00:00,  5.54it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.2909, Val Loss: 0.2245\n\nEpoch 2\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 418/418 [00:44<00:00,  9.30it/s]\n100%|██████████| 53/53 [00:04<00:00, 12.43it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.2225, Val Loss: 0.2148\n\nEpoch 3\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 418/418 [00:44<00:00,  9.42it/s]\n100%|██████████| 53/53 [00:04<00:00, 12.48it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.2151, Val Loss: 0.2098\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 53/53 [00:06<00:00,  7.58it/s]\n","output_type":"stream"},{"name":"stdout","text":"Saved predictions to submission_incep(3).csv\n","output_type":"stream"}],"execution_count":1}]}